# PAA 2024 - Marcio Costa Santos <marciocs@dc.ufmg.br> & Olga NIkolaevna Goussevskaia

livro do cormen e do udi manber

## Aula 1 - 25/09/24

Primeira aula √© pra explicar

- An√°lise e complexidade de algoritmos
- Algoritmos em grafos
- Projetos e Design de algoritmos
- Complexidade de problemas

Os dois primeiros √© dele. As duas √∫ltimas √© com a Olga.

Cada um dos m√≥dulos vale 25 pontos. O primeiro m√≥dulo s√≥ tem uma prova que vale 25. Nos outros ter√° uma prova mais uma atividade, podendo ser uma lista de exerc√≠cios ou um trabalho pr√°tico. Cada professor define de que forma distribui os 25 pontos entre prova e atividade.

Muito provavelmente pra ele ser√° 20 pra prova e 5 pra atividade/lista. Geralmente a Olga faz (20 e 5), e (15, 10)

V√¢o postar o cronograma de PAA no Moodle.

Algumas das avalia√ß√µes s√£o tamb√©m pelo Moodle

Ele geralmente usa slide e tamb√©m escreve muito no quadro. Algumas coisas como algoritmos e desenhos ele prefere ter no slide.

Os slides e as listas ele disponibiliza no Moodle, mesmo que ele n√£o fa√ßa atividades s√≥ de exerc√≠cios. Ele deve fazer duas aulas assim antes de cada uma das provas dos dois primeiros m√≥dulos. Por√©m, tente resolver todos os exerc√≠cios antes das aulas.

Pretende enviar todo o material do m√≥dulo de uma s√≥ vez.

Ele segue um livro e a Olga, outro. Ele gosta de seguir o Cormen "de cabo a rabo".

Ele vai indicar quais cap√≠tulos correspondem √†quela aula.

### Sobre o m√≥dulo

Ela n√£o √© uma disciplina pra aprender a programar, nem √© das mais f√°ceis de teoria.

Exemplo que ele vai fingir que vc sabe: PA, PG, Logaritmo; Estruturas de controle em programa√ß√£o; Estruturas de dados b√°sicos (filha, pilha, √°rvore, heap);

A disciplina √© de An√°lise e constru√ß√£o de algoritmo. A ideia do curso √© que voc√™ j√° entende o b√°sico e vai partir da√≠.

O professor Coutinho criou um material de estudo que √© o "Pr√©-PAA" que tem uma sequ√™ncia de materiais para estudo pr√≥prio. Se n√£o souber de algo, pare e tente resolver.

√â importante seguir o cronograma e fazer isso o mais r√°pido poss√≠vel.

As aulas v√£o come√ßar b√°sicas e elas tendem a se tornar muito complicadas.

Exemplo: Aula 1 √© o b√°sico de grafos. Aula 2 j√° seria a nota√ß√£o matem√°tica para o que foi dado na aula 1.

Ele deve usar bastante transforma√ß√£o de logaritmo.

- Que linguagem de programa√ß√£o √© usada em PAA?
  - Nenhuma. O que ele vai mostrar s√£o algoritmos. Exemplos: `while (deu certo)`, `Inclui V NaLista L`, `R = folhas da √°rvore T`.
  - No in√≠cio ele deve tentar esquematizar mais a parte da estrutura dos dados, mas com o tempo vai se tornar cada vez mais abstrato.

Especialmente em algoritmos recursivos ele vai explicar como funciona o algoritmo, principalmente na ideia, mas faltando alguns passos. Exemplo: ignorando todos os corner-cases e focar na ideia que √© principal.

Python, Java, C ou C++. Ele √© muito fanboy de Julia kkkkkkkkkkkkkkkkkkkkkk

O trabalho provavelmente vai envolver alguma coisa de programa√ß√£o.

- Ele mais se importa que a ideia do algoritmo esteja certa. N√£o importa muito os pormenores. Aqueles √∫ltimos detalhes:
  - Divide em grupos de cinco
    - E se n√£o for m√∫ltiplo?
  - Divide na metade
    - E se for √≠mpar?

A primeira parte da disciplina n√£o √© criar algoritmos, apenas analis√°-los.

Nessa primeira parte √© aquela an√°lise de Big-O para definir a quantidade de passos que o algoritmo executa.

Geralmente vai se utilizar formas matem√°ticas de se utilizar Somat√≥rios, que geralmente s√£o PAs ou PGs.

- √Äs vezes o somat√≥rio √© muito esquisito, que resulta em algo ainda mais esquisito. Exemplo:
  - $\sum^{n}_{i = 0} = \frac{1}{i} = \log n$
  - Mas nesses casos ele geralmente informa que esses "passes de m√°gica" ser√£o utilizados nas provas.

Recurs√£o ser√° muito utilizado. Mesmo algoritmos n√£o recursivos ele tende a escrev√™-las de forma recursiva. Ent√£o, teremos que analisar bem cuidadosamente a complexidade de algoritmos recursivos.

Veremos dois m√©todos para a an√°lise de algoritmos recursivos.

Muitos dos resultados ele tentar√° provar matematicamente que algumas an√°lises est√£o corretas.

Faremos algumas demonstra√ß√µes na disciplina, especialmente nos m√≥dulos 3 e 4, principalmente no 4.

Um dos principais √© prova por indu√ß√£o. Ele tentar√° j√° utilizar algumas provas por indu√ß√£o, especialmente as provas que envolvem grafos na segunda parte da disciplina.

Na primeira parte √© mais conta.

Ele vai tentar n√£o exigir provas matem√°ticas nas avalia√ß√µes, mas geralmente tem na lista. Mesmo que n√£o precise demonstrar, geralmente √© √∫til que se saiba como que acontece para ficar mais f√°cil de entender certas coisas.

Geralmente os alunos tem mais dificuldade nos algoritmos recursivos.

A disciplina ser√° muito corrida √© o tempo da disciplina √© muito curto. Raramente ele demorar√° mais do que uma aula por assunto.

Raramente eles voltar√£o nos assuntos das aulas anteriores.

Se perder alguma aula (Por favor n√£o fa√ßa isso). √â a pior coisa que voc√™ pode fazer nessa disciplina.

Os m√≥dulos geralmente s√£o bem desconexos. Mas num mesmo m√≥dulo, se perder algo, dificilmente vai conseguir recuperar essa informa√ß√£o. Se perdeu algo, vai ter que refazer todas as aulas perdidas antes das aulas posteriores. No primeiro m√≥dulo ainda d√° pra faltar algumas, mas nas pr√≥ximas... üíÄ

Quem n√£o tem acesso ao Moodle, tenha o mais r√°pido poss√≠vel.

Sexta j√° deve ter todos os materiais l√°.

Existe a chance de que mude de sala. E se avisar, ser√° pelo moodle.

### D√∫vidas dos alunos

- Tem monitor?
  - Ele tem X% de certeza que sim, mas ainda n√£o temos. At√© o come√ßo de outubro devem saber quem √©. Geralmente ser√£o na sexta que √© quando estamos mais livres. Ele recomenda fortemente que venhamos nas monitorias. Ele gosta de postar uma lista por semana. √Ä priori elas n√£o valem ponto.
- Enquanto n√£o tem monitor, com quem tirar d√∫vidas?
  - O M√°rcio geralmente tem as manh√£s livres, depois das 8h30 na sala dele 4322 no anexo do DCC. Normalmente √© s√≥ chegar l√° e bater. Sexta ele geralmente t√° aqui o dia todo. Se for algo que demore mais, pode mandar e-mail.
- Vai ter alguma aula de pr√©-PAA ou vai direto na mat√©ria?
  - Ele vai direto na mat√©ria, at√© porque a mat√©ria √© muito extensa.
- Tem v√≠deo-aulas gravadas?
  - Acha que sim, provavelmente o Gabriel Coutinho tem.
- As datas das provas do cronograma est√£o definidas a serem nesses dias mesmo?
  - Sim. Dificilmente mudar√£o a n√£o ser que aconte√ßa algo mt at√≠pico (pandemia/greve). Se acontecer algo com as aulas, ainda d√° pra repor em outros hor√°rios, mas prova √© pouco prov√°vel que se altere.
- A substitutiva [funciona como]?
  - Se voc√™ perder uma avalia√ß√£o, ele sempre abre uma substitutiva para cobrir uma que vc perdeu. Ele costuma deixar que vc fa√ßa a substitutiva mesmo que tenha feito as provas. E a nota da substitutiva sobrescreve a que voc√™ j√° fez, independente de ser maior ou menor.
  - A substitutiva ocorre no s√°bado. Sempre s√°bado de manh√£, normalmente √†s 9h. As provas geralmente s√£o nos hor√°rios de aula. A Olga geralmente prefere fazer as provas no s√°bado tamb√©m.
- O conte√∫do da substitutiva √© qual?
  - O conte√∫do vai ser de acordo com a prova que voc√™ quer substituir.
- Alguma pergunta que n√£o vi
  - Ele vai dizer quais v√£o ser os cap√≠tulos que ele dar√° em cada aula. O livro √© da terceira vers√£o.
- Qual a diferen√ßa entre "PG2" e "PG1_PG2 - Metaturma"?
  - Nenhuma. S√£o duas turmas diferente acontecendo no mesmo hor√°rio, com o mesmo professor, na mesma sala. A Meta-turma √© para reencaminhar os conte√∫dos para as turmas menores.
- E onde enviaremos as atividades?
  - Na Metaturma.
- Qual o cap√≠tulo da aula de segunda?
  - Se n√£o se engana, os cap√≠tulos 2 e 3. E veja tamb√©m os conte√∫dos de pr√©-PAA.

## Aula 2 - 30/09/2024 - [13h08, 14h40]

### Slide: Complexidade de Algoritmos

- Algoritmos no geral ser√£o considerados como fun√ß√µes $f(n)$ que transformam conjunto de entrada em conjunto de sa√≠da.
- Para descrever os algoritmos, ser√£o utilizados pseudoc√≥digos de forma imperativa com estruturas usuais de controle de fluxo.
- atribui√ß√£o como setas e iguais como compara√ß√£o
- Estruturas de dados simples.
- Considera-se mem√≥ria infinita sem se preocupar com a atribui√ß√£o.

D√∫vida 1: Exemplo algoritmo 1: o i=1 seria uma compara√ß√£o ou atribui√ß√£o?

- D√∫vida 2: Exemplo algoritmo 2: Por que a sa√≠da t√° como "?"?
  - Resposta: Para pensarmos sobre o que o algoritmo t√° fazendo, sem dar a resposta de cara.

- Todos os algoritmos ignoram completamente quaisquer dos cornercases que poderiam dar errado: overflow, aloca√ß√£o de mem√≥ria, typechecking, etc.
- O problema do m√≥dulo 1 √© analisar qu√£o bons ou ruins s√£o os algoritmos. Suponho eu que seja a nota√ß√£o de Big-O.
- A complexidade de um algoritmo √© uma fun√ß√£o que descreve o n√∫mero de opera√ß√µes elementares que o algoritmo executa em fun√ß√£o do tamanho da entrada.
- "Custos"
  - Se = Escolha, subconjunto. [Considero que seja algo do tipo um "ou", ou uma multiplica√ß√£o entre as possibilidades.]
  - Para e enquanto: Somat√≥rio
  - Atribui√ß√£o: tempo unit√°rio
  - Matem√°tica e regras: tempo unit√°rio  (a depender da complexidade das regras)
  - Estruturas de dados: Tempo de cada opera√ß√£o.
- O la√ßo tem custo de "2" porque incrementa e compara se chegou na condi√ß√£o.
- No caso do Algoritmo 1, a Fun√ß√£o seria: $F_1(x, n) = 1 + \sum_{i=1}^{n} (2 + 3) = 1 + \sum_{i=1}^{n} (5) = 1 + 5n$.
- No caso do Algoritmo 2, a Fun√ß√£o seria: $F_2(x, n) = 2 + \sum_{i=2}^{n} (1 [checagem do loop] +2 [compara√ß√£o condicional + indexa√ß√£o] +1 [somat√≥rio do iterador]) + \sum_{i=2; se x[i] for par}^{n} (1) [CASOS EM QUE OCORRE A OPERA√á√ÉO *SE*] = 2 + (n-1)*4 [N-1 porque come√ßou i pelo valor 2] + \sum_{i=2; se x[i] for par}^{n} (1)$.
  - Poderia tamb√©m utilizar algo como $\sum_{i=2; se x[i] for par}^{n} (1) = (x[i]\%2)*1$
- Exemplo Algoritmo 3:
  - 1: n*m: preencher a matriz Z NxM
  - 2: compara√ß√£o e incremento do loop i
  - 2: compara√ß√£o e incremento do loop j
  - 8: 2: indexa√ß√£o $z[i][j]$, 2: indexa√ß√£o $x[i][j]$, 2: indexa√ß√£o $y[i][j]$, 1: soma x e y, 1: atribui√ß√£o em $z[i][j]$
  - $F_3(x, y, n, m) = n*m + \sum_{i=1}^{n} (2 + \sum_{j=1}^{m} (2+8)) = n*m + \sum_{i=1}^{n} (2 + 10m) = n*m + 2n + 10nm = 11nm + 2n$

- Inst√¢ncia: conjunto de dados de entrada de um algoritmo: $I$
- Tamanho de uma inst√¢ncia: tamanho em bits da entrada: $I_n$
- Complexidade de um algoritmo: √© a fun√ß√£o que leva o tamanho da inst√¢ncia em...

- Complexidade de pior caso: o maior n√∫mero de passos para uma inst√¢ncia de tamanho $n$.
  - $T(n) = \max_{x \in I_n} F(n, x)$
- Complexidade de melhor caso: o menor n√∫mero de passos para uma inst√¢ncia de tamanho $n$.
  - $T(n) = \min_{x \in I_n} F(n, x)$

D√∫vida: Existe um c√°lculo estat√≠stico de qu√£o prov√°veis de ocorrer s√£o os melhores e maiores casos?
Resposta: Pelo que eu entendi, at√© d√°, s√≥ que √© bem dif√≠cil calcular

- Complexidade de m√©dio caso: o n√∫mero esperado de passos para uma inst√¢ncia de tamanho $n$.
  - $T(n) = \sum_{x \in I_n} P(x)F(n, x)$
  - $P(x)$ √© a probabilidade de ocorrer a inst√¢ncia $x$.
    - "Mas como calcular a probabilidade de uma inst√¢ncia?" "N√£o √© t√£o f√°cil assim"
- Ele sempre considerar√° "complexidade" como sendo "complexidade de pior caso".

- Algoritmo 1:
  - Melhor: [...] 1+5n
  - Pior:  [...] 1+5n
  - M√©dio:  [...] 1+5n
    - Entendi +- como que o F(x, n) foi pra fora do somat√≥rio.
- Algoritmo 2:
  - Melhor: todos elementos s√£o √≠mpares [...] 5n - 4
  - Pior: todos elementos s√£o pares [...] 7n-6
  - M√©dio:  [...] M√≥ trampo. Favor ignorar üòÑüëç

- An√°lise Assint√≥tica
  - O objetivo √© analisar o comportamento de uma fun√ß√£o quando $n$ tende ao infinito.

- D√∫vida: Por que eu compararia n=infinito do pior com o n=infinito do melhor?
- Resposta: Porque no caso, o que a gente t√° comparando √© a melhor e pior distribui√ß√£o dos valores para uma mesma quantidade de elementos. Ent√£o, a gente t√° comparando o melhor caso de uma quantidade de elementos com o pior caso de uma quantidade de elementos.

- Simbolos:
  - $O$
  - $o$
  - $\Theta$
  - $\Omega$

- f = G(g). Essa parte ficou Muito confusa.
- f = O(g) Existem $n_0$ e $c$ tal que: $f(n) \leq c*g(n)$ para todo $n \geq n_0$
  - Entende-se o $c$ como sendo uma forma de chutar o valor de $g$ para cima. E o $n_0$ indica o momento em que $f$ come√ßa a ser menor que $g$.

- Geralmente e procura o menor limite superior assint√≥tico, mas usar outros maiores tamb√©m √© v√°lido. (Menos na prova)
  - $N^k + N^{k-1} \dots + N + 1 = O(N^k)$

Alguns exerc√≠cios ser√£o mostrar valores $C$ e $N_o$ que satisfa√ßam a equa√ß√£o e provem o limite superior.

Geralmente o que ele vai pedir √© encontrar o O() de uma fun√ß√£o.

## Aula 3 - 02/10/2024 - [13h06, 14h40]

- Aulas extras
  - 13h √†s 15h
  - N√£o tem presen√ßa
  - N√£o precisa dos conte√∫dos, mas os conte√∫dos podem ser √∫teis.
  - Ir√£o confirmar quais ser√£o os t√≥picos de cada aula
  - Pontua√ß√£o extra por presen√ßa nas aulas. Muito provavelmente 0,5 ponto por aula.
  - Quase como se fosse aula de pr√©-PAA

### Aula 3: Slide - Aula 2 - Complexidade e Nota√ß√£o Assint√≥tica

- Limite superior
  - $f() = O(g())$ pode ser r√∫sticamente definido como $f() \leq g()$
- Limite superior estrito
  - $f() = o(g())$ pode ser r√∫sticamente definido como $f() < g()$
  - $f = o(g)$ Para todo $c > 0$ existe $n_0$ tal que: $f(n) < c*g(n)$ para todo $n > n_0$
  - √â importante analisar matematicamente de que forma que o descubramos quais os poss√≠veis valores de $C$ e seu respectivo $n_0$.
  - Podemos entender que $n \neq o(n)$ e que $n = O(n)$
- Limite Inferior
  - $f() = \Omega(g())$ pode ser r√∫sticamente definido como $f() \geq g()$
  - Existem $n_0$ e $c$ tal que: $f(n) \geq c*g(n)$ para todo $n \geq n_0$
- Limite Inferior Estrito
  - $f() = \omega(g())$ pode ser r√∫sticamente definido como $f() > g()$
  - Para todo $c > 0$ existe $n_0$ tal que: $f(n) > c*g(n)$ para todo $n > n_0$
- Equival√™ncia
  - $f() = \Theta(g())$ pode ser r√∫sticamente definido como $f() = g()$
  - Existem $n_0$, $c_1$ e $c_2$ tal que: $c_1*g(n) \leq f(n) \leq c_2*g(n)$ para todo $n \geq n_0$
  - Que equivale a dizer que $f() = \Omega(g())$ e $f() = O(g())$
  - Exemplos: $2n^2 + n = \Theta(n^2)$
  - Geralmente busca-se o $\Theta$ de uma fun√ß√£o, mas foca-se mais no $O$.

- Propriedades
  - $k*f(n) = O(f(n))$ para todo $k \in \R$
  - $f(n) * g(n) = O(f(n) * g(n))$
  - $O(f(n)) + O(g(n)) = O(f(n) + g(n))$
  - $O(f(n)) * O(g(n)) = O(f(n) * g(n))$
  - Extra: $O(n)*n = O(n*n) = O(n^2)$

- Entende-se que $O(f(n)) = [conjunto] {g \in F | g = O(f(n))}$
  - Sendo $F$ todas as fun√ß√µes poss√≠veis

- √â importante considerar que os somat√≥rios entre fun√ß√µes √© o somat√≥rio normal. E o somat√≥rio entre $O()$'s √© um tipo de agrupamento entre conjuntos de fun√ß√µes.
- Na prova sempre considerar que estamos buscando o limite mais estrito poss√≠vel.
- Quando n√£o se tem condicional, podemos considerar que o $O()$ √© o mesmo que o $\Omega()$, que s√£o iguais ao $\Theta()$.

### Aula 3: Slide - Aula 3 - Algoritmos Recursivos e Rela√ß√µes de Recorr√™ncia

[JV: O que √© fun√ß√£o de recorr√™ncia?
R Copilot: √â uma fun√ß√£o que √© definida em termos de si mesma. Exemplo: $f(n) = f(n-1) + 1$]

- Sempre consideraremos que $F(1)$ e $F(0)$ s√£o constantes e iguais a $O(1)$, sendo $F$ uma fun√ß√£o recursiva.

- Algoritmo Recursivo 1

```pseudocode
Algoritmo 1: REC
Entrada: inteiro x.
Sa√≠da: ?
se x <= E REC(x-1) >= 1 ent√£o
  RETORNA REC(x-1) + 1
RETORNA 1;  
```

"A parte de encontrar a fun√ß√£o de recorr√™ncia para o algoritmo √© tranquila. O problema √© a an√°lise da parte recursiva"

- Resolu√ß√£o de Recorr√™ncias
  - Podemos resolver equa√ß√µes na forma:
    - 1. $T(n) = aT(n/b) + f(n)$
      - Num caso de divis√£o e conquista, a parte da divis√£o seria o $b$, e a agrega√ß√£o das respostas seria o $a$.
    - 2. $T(n) = aT(n-b) + f(n)$
      - Esse geralmente se refere a casos em que v√° removendo alguns itens de uma estrutura de dados a cada passo.
  - N√£o podemos resolver equa√ß√µes na forma:
    - 3. $T(n) = T(n-a) + T(n-b)$
      - [Tipo Fibonacci]
      - Tendem  a ser ineficientes

$F(n) = F(n-1) + 1$; Condi√ß√£o de parada: $F(1) = 1; F(0) = 1$

$$
F(n) =\\
F(n-1) + 1 =\\
(F(n-2) + 1) + 1 = F(n-2) + 2 =\\
(F(n-3) + 1) + 1 + 1 = F(n-3) + 3 =\\
\vdots\\
F(n) = F(n-k) + k\\
\text{Para n = k}\\
F(k) = F(0) + n = O(1) + n = O(n)
$$

---

$F(n) = F(n-1) + n$

$$
F(n) = F(n-1) + n =\\
(F(n-2) + n-1) + n = F(n-2) + 2n - 1 =\\
(F(n-3) + n-2) + n-1 = F(n-3) + 3n - 2 - 1 =\\
\vdots
F(n-k) + kn - \sum_{i=1}^{k} i=\\
F(0) + n^2 - \sum_{i=1}^{n-1} i \implies \frac{(n-1)*n}{2} \implies O(n^2)
F(0) + n^2 - O(n^2) = O(n^2)
$$

"Teorema mestre"

Revisar PA e PG.

---

D√∫vida: Quando na soma assint√≥tica h√° uma subtra√ß√£o, a gente ignora ela? Sim. Considera-se como se fosse soma normal. Mas a mesma ignor√¢ncia n√£o ocorre na divis√£o e multiplica√ß√£o

### Aula 4: Slide - Aula 3 - Algoritmos Recursivos e Rela√ß√µes de Recorr√™ncia

- $T(n) = T(n - b) + f(n)$
- $T(n) = a * T(\frac{n}{b}) + f(n)$

- Exemplo:
  - $T(n) = 2T(n-4)+5$
    - $T(0) = O(1)$
    - $T(1) = O(1)$
    - $T(2) = O(1)$
    - $T(3) = O(1)$
  - Ele n√£o precisa especificar, nem pretende, mas a ideia √© que todas tenham esses crit√©rios de parada.
  - Resolvendo pelo m√©todo da substitui√ß√£o:

$$
T(n)   = 2( T(n-4)    ) + 5 \\
T(n-4) = 2(2T(n-8) + 5) + 5 = 2^2 T(n-8) + 5*2 + 5 \\
T(n-8) = 2^2 (2T(n-12) + 5) + 5*2 + 4 =  \\
\vdots \\
\text{PASSO K:} 2^k T(n- k*4) + \sum_{i=0}^{k - 1} 2^i*5
$$

- Caso de t√©rmino: n - k*4 = 0; 4k = n; k = n/4
- Complexidade: $2^(n/4) * \Theta(1) + 5 * \sum_{i=0}^{n/4 - 1} 2^i = \Theta(2^{n/4}) + 2^{n/4} - 1 = \Theta(2^{n/4})$

N√£o mexer com constantes em expoentes

- Teorema Mestre
  - Sejam $a \geq 1$ e $b > 1$ constantes, $f(n)$ uma fun√ß√£o, e $T(n) = aT(\frac{n}{b}) + f(n)$, ent√£o, para algum $\epsilon > 0$:
    - Se $f(n) = O(n^{\log_{b}(a) - \epsilon}) \implies T(n) = \Theta(n^{\log_{b}(a)})$ leq
    - Se $f(n) = \Theta(n^{\log_{b}(a)}) \implies T(n) = \Theta(n^{\log_{b}(a)} * log(n))$ =
    - Se $f(n) = \Omega(n^{\log_{b}(a) + \epsilon})$ e $a f (\frac{n}{b}) \leq cf(n)$ ent√£o $\implies T(n) = \Theta(f(n))$ geq

Esse $\epsilon$ quando usa a propriedade de pot√™ncia, torna o caso do Big-O numa divis√£o e o caso do Big-Omega numa multiplica√ß√£o.

- Revisar propriedade de logaritmo

Ele fez dois exemplos no quado que eu n anotei.

- $T(n) = 2T(\frac{n}{2}) + 1$
  - $a = 2; b = 2; f(n) = 1$
  - $\log_{b}(a) = \log_{2}(2) = 1$
  - $n^{\log_{b}a = n^1 = n}$
  - $f(n) = O(n^{\log_{b}(a)})$
  - $1 = O(n^{1-\epsilon}) = \Theta(n)$
- $T(n) = 4T(\frac{n}{4}) + n + 1$
  - $a = 4; b = 4; f(n) = n + 1$
  - $\log_{b}(a) = \log_{4}(4) = 1$
  - $n^{\log_{b}a} = n^1 = n$
  - $f(n) = \Theta(n^{\log_{b} a})$
  - $n+1 = \Theta(n)$
  - $\Theta (n * log n)$

Exerc√≠cio: Descobrir pq que $\log_{b}(n) = O(\log_{2}(n))$ para $b > 1$

- $T(n) = 4T (\frac{n}{2}) + n^3 + n - 5$
  - $a = 4; b = 2; f(n) = n^3 + n - 5$
  - $\log_{b}(a) = \log_{2}(4) = 2$
  - $n^3 + n - 5 = \Omega(n^{2+\epsilon})$
  - $\Theta(f(n)) = \Theta(n^3 + n - 5) = \Theta(n^3)$
- $T(n) = 4T (\frac{n}{2}) + n^2\log_{{2}}(n)$: N√£o d√° pra usar o teorema mestre nessa fun√ß√£o.
  - Tentando usar o teorema mestre
  - $a = 4; b = 2; f(n) = n^2\log_{2}(n)$
  - $\log_{b}(a) = \log_{2}(4) = 2$
  - $n^{\log_{b}(a)} = n^2$
  - $n^2$ e $n^2 * log(n)$ s√£o equivalentes?
  - ... [Tentativa de resolu√ß√£o pelo Teorema Mestre]

Na prova ele espera que se diga "n√£o d√° para usar Teorema Mestre". Ele n√£o espere que se resolva a equa√ß√£o. At√© pode sair abrindo se preferir.

O problema surge quando comparamos o $f(n)$ com a equa√ß√£o com $a$ e $b$ e que a √∫nica diferen√ßa seja o log.

"Tem que ser um polin√¥nimo menor ou maior para ter diferen√ßa entre elas."

Algumas quest√µes n√£o v√£o dar pra fazer. √Äs vezes tem como, mas √© meio tortuoso.

- Exemplo: $T(n) = T(\frac{n}{3}) + T(\frac{n}{4}) + 1$
  - Divide em duas equa√ß√µes falsas do tipo:
    - $F(n) = F(\frac{n}{3}) + F(\frac{n}{3}) + 1 = 2F(\frac{n}{3}) + 1$
    - $G(n) = G(\frac{n}{4}) + G(\frac{n}{4}) + 1 = 2G(\frac{n}{4}) + 1$

- Vai ter gabarito das listas?
  - +-, ele vai tirar d√∫vidas no final. Teremos monitoria e a monitora deve responder boa parte das respostas da lista.

"Essa √© a parte mais f√°cil da mat√©ria"

"Estude isso *freneticamente*"

## Aula 4 - 09/10/2024 - [13h08, 14h47]

### Pr√©-aula 4

- Monitoria possivelmente remota e/ou presencial
- BeeCrowd para trabalhos
- Ele adiantar√° a aula de exerc√≠cios e provavelmente ser√£o 3 horas no s√°bado.
- Alguns t√≥picos extras nas aulas de sexta

### Slide: An√°lise Amortizada

#### Contador Bin√°rio

- Assume que temos um vetor de $n$ bits.
- Este vetor representa um n√∫mero.
- Vamos criar uma fun√ß√£o para incrementar uma unidade no n√∫mero representado.

$$
{1, 3, 4} =
\begin{bmatrix}
  5 && 4 && 3 && 2 && 1 && 0\\
  0 && 1 && 1 && 0 && 1 && 0\\
\end{bmatrix} =
26
$$

$$
{2} =
\begin{bmatrix}
  4 && 3 && 2 && 1 && 0\\
  1 && 1 && 0 && 1 && 0\\
\end{bmatrix} =
4
$$

---

- 0: 0000
- 1: 0001
- 2: 0010
- 3: 0011
- 4: 0100
- 5: 0101
- 6: 0110
- 7: 0111
- 8: 1000

O que o algoritmo faz?

- Enquanto tem um, troca pra zero, quando achar o primeiro zero troca pra um, o resto n√£o faz nada.

#### Algoritmo

...

#### Contador Bin√°rio - Complexidade

- Complexidade de Pior caso: O(n).
- Mas esse pior caso acontece muito raramente...
- As opera√ß√µes t√™m uma rela√ß√£o clara entre elas.
- Seria interessante ter uma liga√ß√£o entre a complexidade e as opera√ß√µes

#### Contador Bin√°rio - An√°lise Amortizada

- Considere o n√∫mero de opera√ß√µes para se realizar uma sequ√™ncia de n opera√ß√µes: $T(n)$.
- Desejamos calcular
  - $\frac{T(n)}{n}$
- Complexidade Amortizada.

D√∫vida: qu√£o distante a complexidade amortizada est√° do caso m√©dio?
Resposta: Razoavelmente distante. Porque nesse caso o output de um √© o input do outro. J√° no caso m√©dio, sorteia-se n√∫meros aleat√≥rios como input.

- Tr√™s m√©todos:
  - (esqueci)
  - M√©todo dos potenciais
  - An√°lise Financeira/M√©todo cont√°vel

---

- Vamos realziar $n$ opera√ß√µes de incremento.
- Calcular o n√∫mero de cada chamada √© complicado.
- Vamos pensar em quantas vezes cada bit √© trocado de 0 para 1 ou vice versa.
- Seja $F(i)$ o n√∫mero de vezes que o bit na posi√ß√£o $i$ √© flipado.

#### Contador Bin√°rio - $F(0)$

- $F(0) = n$
- ...

#### Contador Bin√°rio - $F(1)$

- $F(1) = \frac{n}{2}$
- ...

- $F(2) = \frac{n}{4}$
- $F(3) = \frac{n}{8}$
- ...
- $F(k) = \frac{n}{2^k}$
- ...
- $F(n - 1) = 2$ "Ele volta pra zero" [JV: N√£o entendi muito bem] "Esse $n$ √© relacionado ao tamanho do vetor", aqueles $n$'s acima s√£o da quantidade de opera√ß√µes.

$T(n) = \sum_{i=0}^{n-1} F(i) = \sum_{i=0}^{n-1} \frac{n}{2^i} = n \sum_{i=0}^{n-1} \frac{1}{2^i} \leq 3n$ "N√£o precisa responder isso exatamente"

$\frac{T(n)}{n} \leq \frac{3n}{n} \leq 3 = \Theta(1)$

[JV: Ele se embolou um pouco na nota√ß√£o dos √≠ndices e quantidades de opera√ß√µes]

Na teoria, deveria ser $\lim_{n \cond \inf} \frac{T(n)}{n}$, mas ele vai ignorar o limite.

#### M√©todo do Potencial

- VAmos atribuir uma energia potencial para a estrutura de dados.
- Temos uma fun√ß√£o que calcula esse potencial $\phi()$.
- Seja $D_0$ uma estrutura de dados, temos $\phi(D_0)$.
- Vamos realizar $n$ opera√ß√µes com essa estrutura.
- Seja $D_i$ √© a estrutura ap√≥s a i-√©sima opera√ß√£o.

---

... [N√£o anotei]

---

... [N√£o anotei]

Consideramos que a energia potencial √© a quantidade de bits que est√£o em 1.

---

- $b_0 = 0$ e $b_n = k$
- $b_i = b_{i-1} - t_i + 1$ isso significa que $b_i - b_{i-1} = -t_i + 1$
- $c^{\^}_i = c_i + \Phi(D_i) - \Phi(D_{i-1}) = t_i + 1 + (-t_i + 1) = 2$

D√∫vida Manu: de que forma √© definido o que √© uma opera√ß√£o?

#### M√©todo Cont√°vel

- Vamos analisar o nosso contador Bin√°rio.
- Vamos modificar os custos do nosso programa.
- Vamos assumir que flipar um bit para 1 custa 2.
- Por que?
- Porque vamos mudar umbit para 0 de gra√ßa!

A l√≥gica disso √© que em cada execu√ß√£o da fun√ß√£o, apenas h√° uma mudan√ßa de 0 para 1, ent√£o, cada uma das opera√ß√µes custa exatamente 2.

Esse √∫ltimo m√©todo nem sempre √© o mais direto, mas deve-ser ter cuidado na hora de se equilibrar as opera√ß√µes.

"Pode sempre ter lucro, o problema √© ficar no vermelho"

---

Fim da mat√©ria da P1

## Estudar

- Material de Pr√©-PAA
- Heap
- Transforma√ß√£o de logaritmo
- Propriedades de logaritmo
- Soma de PA e PG

## D√∫vidas

$O(n!)$ isn't equivalent to $O(n^n)$. It is asymptotically less than $O(n^n)$.

$O(\log(n!))$ is equal to $O(n \log(n))$. Here is one way to prove that:

Note that by using the log rule $\log(mn) = \log(m) + \log(n)$ we can see that:

$\log(n!) = \log(n*(n-1)*...2*1) = \log(n) + \log(n-1) + ... \log(2) + \log(1)$

Proof that $O(\log(n!)) \subseteq O(n \log(n))$:

$\log(n!) = \log(n) + \log(n-1) + ... \log(2) + \log(1)$

Which is less than:

$\log(n) + \log(n) + \log(n) + \log(n) + ... + \log(n) = n*\log(n)$

So $O(\log(n!))$ is a subset of $O(n \log(n))$

Proof that $O(n \log(n)) \subseteq O(\log(n!))$:

$\log(n!) = \log(n) + \log(n-1) + \dots \log(2) + \log(1)$

Which is greater than the left half of that expression with all $(n-x)$ replaced by $n/2$:

$\log(n/2) + \log(n/2) + ... + \log(n/2) = floor(n/2)*\log(floor(n/2)) \in O(n \log(n))$

So $O(n \log(n))$ is a subset of O(\log(n!))$.

Since $O(n \log(n)) \subseteq O(\log(n!)) \subseteq O(n \log(n))$, they are equivalent big-Oh classes.
